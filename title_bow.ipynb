{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "from collections import defaultdict\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load term matrix\n",
    "with open('data/title_matrix.pkl', 'rb') as f:\n",
    "    matrix = pickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "# load original reviews df\n",
    "with open('data/reviews_processed.pkl', 'rb') as f:\n",
    "    reviews = pickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "# load look-up dict\n",
    "with open('data/title_key.pkl', 'rb') as f:\n",
    "    vocab = pickle.load(f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.index = pd.RangeIndex(len(reviews.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter reviews without title\n",
    "with_title = reviews[reviews['clean_title'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_idx = reviews[reviews['clean_title'] != ''].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new df\n",
    "y = with_title['star_rating']\n",
    "\n",
    "# Try product department instead of class\n",
    "X = pd.DataFrame({'class':with_title['product_category_department'],\n",
    "                  'upvotes':with_title['upvotes']})\n",
    "\n",
    "# change to a 3 class problem\n",
    "new_ys = []\n",
    "for score in y:\n",
    "    if score < 3:\n",
    "        new_ys.append(0)\n",
    "    elif score == 3:\n",
    "        new_ys.append(1)\n",
    "    else:\n",
    "        new_ys.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "455bc25712584e03a8cffcf1cca64b96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Adding data to columns', max=3057, style=ProgressStyle(descriâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# create df for features\n",
    "lemmas = pd.DataFrame(columns=vocab.keys())\n",
    "for c in tqdm(lemmas.columns.values, desc='Adding data to columns'):\n",
    "    vocab_index = vocab[c]\n",
    "    data = []\n",
    "    for i in filtered_idx:\n",
    "        data.append(matrix[(i-1, vocab_index)])\n",
    "    lemmas[c] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reset_index(drop=True)\n",
    "lemmas = lemmas.reset_index(drop=True)\n",
    "X_feats = pd.concat([X, lemmas], axis=1)\n",
    "\n",
    "# make product class dummy variable\n",
    "prod_class = pd.get_dummies(X['class'])\n",
    "prod_class = prod_class.reset_index(drop=True)\n",
    "\n",
    "# drop original class columns\n",
    "# concat prod_class\n",
    "X_feats.drop('class', axis=1, inplace=True)\n",
    "X_feats = pd.concat([X_feats, prod_class], axis=1)\n",
    "\n",
    "X_feats.to_csv(\"data/title_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype uint8, int64, object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype uint8, int64, object were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:8: DataConversionWarning: Data with input dtype uint8, int64, object were all converted to float64 by StandardScaler.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_feats, new_ys, test_size=0.2)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, classification_report, mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Fit Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Fit Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(solver='lbfgs', \n",
    "                        multi_class='multinomial', \n",
    "                        n_jobs=-1)\n",
    "lr.fit(x_train, y_train)\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "F1_Weighted 0.6656767040982435\n",
      "Accuracy 0.7440914866581957\n",
      "MAE 0.37229987293519695\n",
      "****************************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Bad       0.14      0.02      0.04       423\n",
      "     Neutral       0.18      0.03      0.05       496\n",
      "        Good       0.77      0.96      0.85      3016\n",
      "\n",
      "   micro avg       0.74      0.74      0.74      3935\n",
      "   macro avg       0.36      0.34      0.32      3935\n",
      "weighted avg       0.63      0.74      0.67      3935\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "y_preds = rf.predict(x_test)\n",
    "rf_f1 = f1_score(y_test, y_preds, average='weighted')\n",
    "rf_acc = accuracy_score(y_test, y_preds)\n",
    "rf_mae = mean_absolute_error(y_test, y_preds)\n",
    "\n",
    "print(\"Random Forest\")\n",
    "print(\"F1_Weighted\", rf_f1)\n",
    "print(\"Accuracy\", rf_acc)\n",
    "print(\"MAE\", rf_mae)\n",
    "print(\"*\"*40)\n",
    "\n",
    "classes = ['Bad', 'Neutral', 'Good']\n",
    "print(classification_report(y_test, y_preds, target_names=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "F1_Weighted 0.6604496662980864\n",
      "Accuracy 0.737738246505718\n",
      "MAE 0.3801778907242694\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Bad       0.08      0.01      0.02       423\n",
      "     Neutral       0.14      0.03      0.05       496\n",
      "        Good       0.77      0.96      0.85      3016\n",
      "\n",
      "   micro avg       0.74      0.74      0.74      3935\n",
      "   macro avg       0.33      0.33      0.31      3935\n",
      "weighted avg       0.61      0.74      0.66      3935\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "y_preds = lr.predict(x_test)\n",
    "lr_f1 = f1_score(y_test, y_preds, average='weighted')\n",
    "lr_acc = accuracy_score(y_test, y_preds)\n",
    "lr_mae = mean_absolute_error(y_test, y_preds)\n",
    "print(\"Logistic Regression\")\n",
    "print(\"F1_Weighted\", lr_f1)\n",
    "print(\"Accuracy\", lr_acc)\n",
    "print(\"MAE\", lr_mae)\n",
    "\n",
    "classes = ['Bad', 'Neutral', 'Good']\n",
    "print(classification_report(y_test, y_preds, target_names=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli NB\n",
      "F1_Weighted 0.6575100249628001\n",
      "Accuracy 0.7415501905972046\n",
      "MAE 0.3761118170266836\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Bad       0.03      0.00      0.01       423\n",
      "     Neutral       0.07      0.01      0.02       496\n",
      "        Good       0.77      0.97      0.85      3016\n",
      "\n",
      "   micro avg       0.74      0.74      0.74      3935\n",
      "   macro avg       0.29      0.33      0.29      3935\n",
      "weighted avg       0.60      0.74      0.66      3935\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Bernoulli NaivesBayes\n",
    "y_preds = bnb.predict(x_test)\n",
    "bnb_f1 = f1_score(y_test, y_preds, average='weighted')\n",
    "bnb_acc = accuracy_score(y_test, y_preds)\n",
    "bnb_mae = mean_absolute_error(y_test, y_preds)\n",
    "print(\"Bernoulli NB\")\n",
    "print(\"F1_Weighted\", bnb_f1)\n",
    "print(\"Accuracy\", bnb_acc)\n",
    "print(\"MAE\", bnb_mae)\n",
    "\n",
    "classes = ['Bad', 'Neutral', 'Good']\n",
    "print(classification_report(y_test, y_preds, target_names=classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
