{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "from collections import defaultdict\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "# nltk.download('sentiwordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data/vocab_key.pkl', 'rb') as f:\n",
    "    vocab = pickle.load(f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/term_matrix.pkl', 'rb') as f:\n",
    "    matrix = pickle.load(f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<absolutely.r.01: PosScore=0.5 NegScore=0.0>\n"
     ]
    }
   ],
   "source": [
    "print(swn.senti_synset('absolutely.r.01'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cleaned reviews\n",
    "reviews = pd.read_pickle(\"data/reviews_processed.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_scores = defaultdict(float)\n",
    "stemmer = nltk.PorterStemmer()\n",
    "pos_interest = ['ADJ','NOUN', 'VERB', 'ADV']\n",
    "\n",
    "def sentiment_score(doc_id, text):\n",
    "    review = nlp(text)\n",
    "    tokens = []\n",
    "    for t in review:\n",
    "        if not t.is_stop and t.is_alpha and t.pos_ in pos_interest:\n",
    "            t_stem = stemmer.stem(t.text)\n",
    "            if t_stem in vocab.keys():\n",
    "                if t.pos_ == 'ADJ':\n",
    "                    pos = 'a'\n",
    "                elif t.pos_ == 'ADV':\n",
    "                    pos = 'r'\n",
    "                elif t.pos_ == 'VERB':\n",
    "                    pos = 'v'\n",
    "                elif t.pos == 'NOUN':\n",
    "                    pos = 'n'\n",
    "                try:\n",
    "                    senti_text =  list(swn.senti_synsets(t.lemma_, pos))[0]\n",
    "                    vocab_index = vocab[t_stem]\n",
    "                    agg_score = senti_text.pos_score() - senti_text.neg_score()\n",
    "                    # update matrix values\n",
    "                    if agg_score != 0:\n",
    "                        matrix[(doc_id, vocab_index)] *= agg_score\n",
    "                except:\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d34efd4ac384407cb55cd80ee9dbc529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Updating Matrix Score', max=1, style=Progre…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/scipy/sparse/_index.py:69: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# update matrix for all docs\n",
    "for i, row in tqdm(reviews.iterrows(), desc='Updating Matrix Score', total=len(reviews)):\n",
    "    sentiment_score(i, row['review_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('data/senti_matrix.pkl', 'wb') as f:\n",
    "#     pickle.dump(matrix, f)\n",
    "#     f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/senti_matrix.pkl', 'rb') as f:\n",
    "    senti_matrix = pickle.load(f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:  0.1798195970823628\n",
      "After:  0.0899097985411814\n"
     ]
    }
   ],
   "source": [
    "# check if update works\n",
    "\n",
    "idx = vocab['absolut']\n",
    "print(\"Before: \", matrix[(0, idx)])\n",
    "print(\"After: \", senti_matrix[(0, idx)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new df\n",
    "y = reviews['star_rating']\n",
    "\n",
    "# Try product department instead of class\n",
    "X = pd.DataFrame({'class':reviews['product_category_department'],\n",
    "                  'upvotes':reviews['upvotes']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df for features\n",
    "lemmas = pd.DataFrame(columns=vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "930c33fe2ae14bc4971d63b27ed60a26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Adding data to columns', max=2000, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "NUM_DOCS = len(X)\n",
    "\n",
    "for c in tqdm(lemmas.columns.values, desc='Adding data to columns'):\n",
    "    vocab_index = vocab[c]\n",
    "    data = []\n",
    "    for i in range(NUM_DOCS):\n",
    "        data.append(senti_matrix[(i, vocab_index)])\n",
    "    lemmas[c] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reset_index(drop=True)\n",
    "lemmas = lemmas.reset_index(drop=True)\n",
    "X_feats = pd.concat([X, lemmas], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make product class dummy variable\n",
    "prod_class = pd.get_dummies(X['class'])\n",
    "prod_class = prod_class.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop original class columns\n",
    "# concat prod_class\n",
    "X_feats.drop('class', axis=1, inplace=True)\n",
    "X_feats = pd.concat([X_feats, prod_class], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_feats.to_csv(\"data/senti_features.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
