{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict\n",
    "from spellchecker import SpellChecker\n",
    "import emoji\n",
    "import spacy\n",
    "import textacy\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Read in data\n",
    "import pickle\n",
    "with open('data/reviews_clean.pkl', 'rb') as f:\n",
    "    reviews = pickle.load(f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm 5\"5' and 125 lbs. i ordered the s petite to make sure the length wasn't too long. i typically wear an xs regular in retailer dresses. if you're less busty (34b cup or smaller), a s petite will fit you perfectly (snug, but not tight). i love that i could dress it up for a party, or down for work. i love that the tulle is longer then the fabric underneath.\n"
     ]
    }
   ],
   "source": [
    "for r in reviews['review_text']:\n",
    "    if 'lb' in r:\n",
    "        print(r)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rules for Text Cleaning:\n",
    "- Short hand abbrev:\n",
    "    + bc -> because\n",
    "- Repeating words (sooo):\n",
    "    + regex??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add special case rule\n",
    "from spacy.attrs import ORTH, LEMMA, POS\n",
    "\n",
    "special_case = [{ORTH: u\"bc\", LEMMA: u\"because\", POS: u\"CONJ\"}]\n",
    "nlp.tokenizer.add_special_case(u\"bc\", special_case)\n",
    "\n",
    "suffixes = nlp.Defaults.suffixes + (r'''lb|cm|\\\"''',)\n",
    "suffix_regex = spacy.util.compile_suffix_regex(suffixes)\n",
    "nlp.tokenizer.suffix_search = suffix_regex.search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i am number number and number lbs i ordered the s petite to make sure the length wasn t too long i typically wear an xs regular in retailer dresses if you are less busty 34b cup or smaller a s petite will fit you perfectly snug but not tight i love that i could dress it up for a party or down for work i love that the tulle is longer then the fabric underneath'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"I'm 5\"5' and 125 lbs. i ordered the s petite to make sure the length wasn't too long. i typically wear an xs regular in retailer dresses. if you're less busty (34b cup or smaller), a s petite will fit you perfectly (snug, but not tight). i love that i could dress it up for a party, or down for work. i love that the tulle is longer then the fabric underneath.\n",
    "\"\"\"\n",
    "textacy.preprocess.preprocess_text(text, False, \n",
    "                                              lowercase=True, no_urls=True, \n",
    "                                              no_emails=True, no_phone_numbers=True, \n",
    "                                              no_numbers=True, no_currency_symbols=True, \n",
    "                                              no_punct=True, no_contractions=False, \n",
    "                                              no_accents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = emoji.demojize(text)\n",
    "    text = textacy.preprocess.preprocess_text(text, False, \n",
    "                                              lowercase=True, no_urls=True, \n",
    "                                              no_emails=True, no_phone_numbers=True, \n",
    "                                              no_numbers=True, no_currency_symbols=False, \n",
    "                                              no_punct=True, no_contractions=False, \n",
    "                                              no_accents=True)\n",
    "    # remove unit of measurement\n",
    "    text = re.sub('lb[s]?', '', text)\n",
    "    text = re.sub('[0-9]{1,2}[\\w]*', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7b3dbfa326348b0b0abfa837679e4e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=22641), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "reviews['clean_text'] = reviews['review_text'].progress_apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.to_pickle('data/reviews_processed.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "analyzer = TfidfVectorizer().build_analyzer()\n",
    "stemmer = nltk.stem.WordNetLemmatizer()\n",
    "def stemmed_words(doc):\n",
    "    return list(map(stemmer.lemmatize, analyzer(doc)) )\n",
    "\n",
    "# vectorizer = TfidfVectorizer(ngram_range=(1,2), \n",
    "#                              stop_words='english',\n",
    "#                              analyzer=stemmed_words,\n",
    "#                              norm='l1')\n",
    "# corpus = list(reviews['clean_text'])\n",
    "\n",
    "# X = vectorizer.fit_transform(tqdm(corpus, desc='Calculating TF-iDF', total=len(reviews)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22641, 9694)\n"
     ]
    }
   ],
   "source": [
    "#12613 unique lemmas\n",
    "#9694 unique Porter stems\n",
    "#8190 unique Lancaster stems\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will go with Porter stemming because not much difference to Lancaster while retaining more meaning of words\n",
    "\n",
    "Only considers top 3000 stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3f231559a7f44189a5bd978c88d3d89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Calculating TF-iDF', max=22641, style=ProgressStyle(descriptiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), \n",
    "                             stop_words='english',\n",
    "                             analyzer=stemmed_words,\n",
    "                             max_features=1000,\n",
    "                             norm='l1')\n",
    "corpus = list(reviews['clean_text'])\n",
    "\n",
    "X = vectorizer.fit_transform(tqdm(corpus, desc='Calculating TF-iDF', total=len(reviews)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/term_matrix.pkl', 'wb') as f:\n",
    "    pickle.dump(X, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/vocab_key.pkl', 'wb') as f:\n",
    "    pickle.dump(vectorizer.vocabulary_, f)\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
